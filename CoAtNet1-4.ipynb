{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoAtNet-tf 88.00%.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFNLhaNHBHTw",
        "outputId": "4c8b084b-d3e8-453f-be4c-1b1981998b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW9nzd2j806z"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "#os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "u57ZKLmlQh9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall tensorflow -y\n",
        "#pip uninstall keras\n",
        "# Try to switch the version of tensorflow and kera\n",
        "#pip install tf-nightly\n",
        "#pip install keras==2.6.0\n",
        "#!pip install  tensorflow==2.6\n",
        "#tf.config.set_visible_devices([], 'GPU')"
      ],
      "metadata": {
        "id": "f-TVPreOxxWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CoAtNet\n",
        "class MBConv(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, strides = 1, expand_ratio = 1, se_ratio = 4, residual = True, momentum = 0.9, epsilon = 0.01, convolution = tf.keras.layers.Conv2D, activation = tf.nn.swish, kernel_initializer = \"he_normal\", **kwargs):\n",
        "        super(MBConv, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.expand_ratio = expand_ratio\n",
        "        self.se_ratio = se_ratio\n",
        "        self.residual = residual\n",
        "        self.momentum = momentum\n",
        "        self.epsilon = epsilon\n",
        "        self.convolution = convolution\n",
        "        self.activation = activation\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.layers = []\n",
        "        self.post = []\n",
        "        if self.expand_ratio != 1:\n",
        "            conv = self.convolution(input_shape[-1] * self.expand_ratio, 1, use_bias = False, kernel_initializer = self.kernel_initializer)\n",
        "            norm = tf.keras.layers.BatchNormalization(momentum = self.momentum, epsilon = self.epsilon)\n",
        "            act = tf.keras.layers.Activation(self.activation)\n",
        "            input_shape = input_shape[:-1] + (input_shape[-1] * self.expand_ratio,)\n",
        "            self.layers += [conv, norm, act]\n",
        "        \n",
        "        #Depthwise Convolution\n",
        "        conv = self.convolution(input_shape[-1], self.kernel_size, strides = self.strides, groups = input_shape[-1], padding = \"same\", use_bias = False, kernel_initializer = self.kernel_initializer)\n",
        "        norm = tf.keras.layers.BatchNormalization(momentum = self.momentum, epsilon = self.epsilon)\n",
        "        act = tf.keras.layers.Activation(self.activation)\n",
        "        self.layers += [conv, norm, act]\n",
        "        \n",
        "        #Squeeze and Excitation layer, if desired\n",
        "        axis = list(range(1, len(input_shape) - 1))\n",
        "        gap = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis = axis, keepdims = True))\n",
        "        squeeze = self.convolution(max(1, int(input_shape[-1] / self.se_ratio)), 1, use_bias = True, kernel_initializer = self.kernel_initializer)\n",
        "        act = tf.keras.layers.Activation(self.activation)\n",
        "        excitation = self.convolution(input_shape[-1], 1, use_bias = True, kernel_initializer = self.kernel_initializer)\n",
        "        se = lambda x: x * tf.nn.sigmoid(excitation(act(squeeze(gap(x)))))\n",
        "        self.layers += [se]\n",
        "        \n",
        "        #Output Phase\n",
        "        conv = self.convolution(self.filters, 1, use_bias = False, kernel_initializer = self.kernel_initializer)\n",
        "        norm = tf.keras.layers.BatchNormalization(momentum = self.momentum, epsilon = self.epsilon)\n",
        "        self.layers += [conv, norm]\n",
        "        \n",
        "        #Residual\n",
        "        if self.residual:\n",
        "            if 1 < self.strides:\n",
        "                pool = tf.keras.layers.MaxPool2D(pool_size = self.strides + 1, strides = self.strides, padding = \"same\")\n",
        "                self.post.append(pool)\n",
        "            if input_shape[-1] != self.filters:\n",
        "                resample = self.convolution(self.filters, 1, use_bias = False, kernel_initializer = self.kernel_initializer)\n",
        "                self.post.append(resample)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = x\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "            \n",
        "        if self.residual:\n",
        "            for layer in self.post:\n",
        "                x = layer(x)\n",
        "            out = out + x\n",
        "        return out\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super(MBConv, self).get_config()\n",
        "        config[\"filters\"] = self.filters\n",
        "        config[\"kernel_size\"] = self.kernel_size\n",
        "        config[\"expand_ratio\"] = self.expand_ratio\n",
        "        config[\"se_ratio\"] = self.se_ratio\n",
        "        config[\"residual\"] = self.residual\n",
        "        config[\"momentum\"] = self.momentum\n",
        "        config[\"epsilon\"] = self.epsilon\n",
        "        config[\"convolution\"] = self.convolution\n",
        "        config[\"activation\"] = self.activation\n",
        "        config[\"kernel_initializer\"] = self.kernel_initializer\n",
        "        return config\n",
        "\n",
        "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, emb_dim = 768, n_head = 12, out_dim = None, relative_window_size = None, dropout_rate = 0., kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0, stddev = 0.01), **kwargs):\n",
        "        #ScaledDotProductAttention\n",
        "        super(MultiHeadSelfAttention, self).__init__(**kwargs)\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_head = n_head\n",
        "        if emb_dim % n_head != 0:\n",
        "            raise ValueError(\"Shoud be embedding dimension % number of heads = 0.\")\n",
        "        if out_dim is None:\n",
        "            out_dim = self.emb_dim\n",
        "        self.out_dim = out_dim\n",
        "        if relative_window_size is not None and np.ndim(relative_window_size) == 0:\n",
        "            relative_window_size = [relative_window_size, relative_window_size]\n",
        "        self.relative_window_size = relative_window_size\n",
        "        self.projection_dim = emb_dim // n_head\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.query = tf.keras.layers.Dense(emb_dim, kernel_initializer = kernel_initializer)\n",
        "        self.key = tf.keras.layers.Dense(emb_dim, kernel_initializer = kernel_initializer)\n",
        "        self.value = tf.keras.layers.Dense(emb_dim, kernel_initializer = kernel_initializer)\n",
        "        self.combine = tf.keras.layers.Dense(out_dim, kernel_initializer = kernel_initializer)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        if self.relative_window_size is not None:\n",
        "            self.relative_position_bias_table = self.add_weight(\"relative_position_bias_table\", shape = [((2 * self.relative_window_size[0]) - 1) * ((2 * self.relative_window_size[1]) - 1), self.n_head], trainable = self.trainable)\n",
        "            coords_h = np.arange(self.relative_window_size[0])\n",
        "            coords_w = np.arange(self.relative_window_size[1])\n",
        "            coords = np.stack(np.meshgrid(coords_h, coords_w, indexing = \"ij\")) #2, Wh, Ww\n",
        "            coords = np.reshape(coords, [2, -1])\n",
        "            relative_coords = np.expand_dims(coords, axis = -1) - np.expand_dims(coords, axis = -2) #2, Wh * Ww, Wh * Ww\n",
        "            relative_coords = np.transpose(relative_coords, [1, 2, 0]) #Wh * Ww, Wh * Ww, 2\n",
        "            relative_coords[:, :, 0] += self.relative_window_size[0] - 1 #shift to start from 0\n",
        "            relative_coords[:, :, 1] += self.relative_window_size[1] - 1\n",
        "            relative_coords[:, :, 0] *= 2 * self.relative_window_size[1] - 1\n",
        "            relative_position_index = np.sum(relative_coords, -1)\n",
        "            self.relative_position_index = tf.Variable(tf.convert_to_tensor(relative_position_index), trainable = False, name= \"relative_position_index\")\n",
        "        \n",
        "    def attention(self, query, key, value, relative_position_bias = None):\n",
        "        score = tf.matmul(query, key, transpose_b = True)\n",
        "        n_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(n_key)\n",
        "        if relative_position_bias is not None:\n",
        "            scaled_score = scaled_score + relative_position_bias\n",
        "        weight = tf.nn.softmax(scaled_score, axis = -1)\n",
        "        if 0 < self.dropout_rate:\n",
        "            weight = tf.nn.dropout(weight, self.dropout_rate)\n",
        "        out = tf.matmul(weight, value)\n",
        "        return out\n",
        "    \n",
        "    def separate_head(self, x):\n",
        "        out = tf.keras.layers.Reshape([-1, self.n_head, self.projection_dim])(x)\n",
        "        out = tf.keras.layers.Permute([2, 1, 3])(out)\n",
        "        return out\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        query = self.query(inputs)\n",
        "        key = self.key(inputs)\n",
        "        value = self.value(inputs)\n",
        "        \n",
        "        query = self.separate_head(query)\n",
        "        key = self.separate_head(key)\n",
        "        value = self.separate_head(value)\n",
        "        \n",
        "        relative_position_bias = None\n",
        "        if self.relative_window_size is not None:\n",
        "            relative_position_bias = tf.gather(self.relative_position_bias_table, tf.reshape(self.relative_position_index, [-1]))\n",
        "            relative_position_bias = tf.reshape(relative_position_bias, [self.relative_window_size[0] * self.relative_window_size[1], self.relative_window_size[0] * self.relative_window_size[1], -1]) #Wh * Ww,Wh * Ww, nH\n",
        "            relative_position_bias = tf.transpose(relative_position_bias, [2, 0, 1]) #nH, Wh * Ww, Wh * Ww\n",
        "            relative_position_bias = tf.expand_dims(relative_position_bias, axis = 0)\n",
        "        attention = self.attention(query, key, value, relative_position_bias)\n",
        "        attention = tf.keras.layers.Permute([2, 1, 3])(attention)\n",
        "        attention = tf.keras.layers.Reshape([-1, self.emb_dim])(attention)\n",
        "        \n",
        "        out = self.combine(attention)\n",
        "        return out\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super(MultiHeadSelfAttention, self).get_config()\n",
        "        config[\"emb_dim\"] = self.emb_dim\n",
        "        config[\"n_head\"] = self.n_head\n",
        "        config[\"out_dim\"] = self.out_dim\n",
        "        config[\"relative_window_size\"] = self.relative_window_size\n",
        "        config[\"projection_dim\"] = self.projection_dim\n",
        "        config[\"dropout_rate\"] = self.dropout_rate\n",
        "        return config\n",
        "        \n",
        "class ConvTransformer(tf.keras.layers.Layer):\n",
        "    def __init__(self, emb_dim = 768, n_head = 12, strides = 1, out_dim = None, epsilon = 1e-5, dropout_rate = 0., activation = tf.keras.activations.gelu, kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0, stddev = 0.01), **kwargs):\n",
        "        super(ConvTransformer, self).__init__(**kwargs)\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_head = n_head\n",
        "        self.strides = strides\n",
        "        self.out_dim = out_dim if out_dim is not None else emb_dim\n",
        "        self.epsilon = epsilon\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.activation = activation\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.attention = []\n",
        "        self.residual = []\n",
        "        \n",
        "        #Attention\n",
        "        shape = input_shape[1:3]\n",
        "        if 1 < self.strides:\n",
        "            shape = np.divide(np.add(shape, (self.strides - 1)), self.strides).astype(int)\n",
        "            pool = tf.keras.layers.MaxPool2D(pool_size = self.strides + 1, strides = self.strides, padding = \"same\")\n",
        "            self.attention.append(pool)\n",
        "            self.residual.append(pool)\n",
        "        if input_shape[-1] != self.out_dim:\n",
        "            resample = tf.keras.layers.Conv2D(self.out_dim, 1, padding = \"same\", use_bias = False, kernel_initializer = \"he_normal\")\n",
        "            self.residual.append(resample)\n",
        "        pre_reshape = tf.keras.layers.Reshape([-1, input_shape[-1]])\n",
        "        mhsa = MultiHeadSelfAttention(emb_dim = self.emb_dim, n_head = self.n_head, out_dim = self.out_dim, relative_window_size = shape, dropout_rate = self.dropout_rate)\n",
        "        post_reshape = tf.keras.layers.Reshape([*shape, self.out_dim])\n",
        "        self.attention += [pre_reshape, mhsa, post_reshape]\n",
        "        \n",
        "        self.ffn = []\n",
        "        #Feed Forward Network\n",
        "        norm = tf.keras.layers.LayerNormalization(epsilon = self.epsilon)\n",
        "        dense1 = tf.keras.layers.Dense(self.out_dim, kernel_initializer = self.kernel_initializer)\n",
        "        act = tf.keras.layers.Activation(self.activation)\n",
        "        dense2 = tf.keras.layers.Dense(self.out_dim, kernel_initializer = self.kernel_initializer)\n",
        "        self.ffn = [norm, dense1, act, dense2]\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        out = inputs\n",
        "        for layer in self.attention:\n",
        "            out = layer(out)\n",
        "        for layer in self.residual:\n",
        "            inputs = layer(inputs)\n",
        "        out = out + inputs\n",
        "        \n",
        "        for layer in self.ffn:\n",
        "            out = layer(out)\n",
        "        return out\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super(ConvTransformer, self).get_config()\n",
        "        config[\"emb_dim\"] = self.emb_dim\n",
        "        config[\"n_head\"] = self.n_head\n",
        "        config[\"strides\"] = self.strides\n",
        "        config[\"out_dim\"] = self.out_dim\n",
        "        config[\"epsilon\"] = self.epsilon\n",
        "        config[\"dropout_rate\"] = self.dropout_rate\n",
        "        config[\"activation\"] = self.activation\n",
        "        config[\"kernel_initializer\"] = self.kernel_initializer\n",
        "        return config\n",
        "    \n",
        "def coatnet(x, n_class = 1000, include_top = True, n_depth = [2, 2, 6, 14, 2], n_feature = [64, 96, 192, 384, 768], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu, name = \"\"):\n",
        "    #block : S > Stem, C > MBConv, T > Transformer\n",
        "    if 0 < len(name):\n",
        "        name += \"_\"\n",
        "    if isinstance(stage_stride_size, int):\n",
        "        stage_stride_size = [stage_stride_size] * len(block)\n",
        "        \n",
        "    out = x\n",
        "    for i, (_n_depth, _n_feature, _block, _stage_stride_size) in enumerate(zip(n_depth, n_feature, block, stage_stride_size)):\n",
        "        for j in range(_n_depth):\n",
        "            stride_size = 1 if j != 0 else _stage_stride_size\n",
        "            residual = out\n",
        "            if _block.upper() == \"C\":# i == 0:\n",
        "                out = tf.keras.layers.Conv2D(_n_feature, 1 if i != 0 else 3, strides = stride_size, padding = \"same\", use_bias = False, kernel_initializer = \"he_normal\", name = \"{0}stage{1}_conv{2}\".format(name, i, j + 1))(out)\n",
        "                out = tf.keras.layers.BatchNormalization(momentum = 0.9, epsilon = 1e-5, name = \"{0}stage{1}_norm{2}\".format(name, i, j + 1))(out)\n",
        "                out = tf.keras.layers.Activation(activation, name = \"{0}stage{1}_act{2}\".format(name, i, j + 1))(out)\n",
        "            elif _block.upper() == \"M\":\n",
        "                out = tf.keras.layers.BatchNormalization(momentum = 0.9, epsilon = 1e-5, name = \"{0}stage{1}_pre_norm{2}\".format(name, i, j + 1))(out)\n",
        "                out = MBConv(_n_feature, 3, strides = stride_size, expand_ratio = expand_ratio, se_ratio = se_ratio, residual = True, momentum = 0.9, epsilon = 1e-5, activation = activation, name = \"{0}stage{1}_mbconv{2}\".format(name, i, j + 1))(out)\n",
        "            elif _block.upper() == \"T\":\n",
        "                out = tf.keras.layers.LayerNormalization(epsilon = 1e-5, name = \"{0}stage{1}_pre_norm{2}\".format(name, i, j + 1))(out)\n",
        "                out = ConvTransformer(32 * 8, 8, strides = stride_size, out_dim = _n_feature, epsilon = 1e-5, activation = activation, name = \"{0}stage{1}_transformer{2}\".format(name, i, j + 1))(out)\n",
        "\n",
        "    if include_top:\n",
        "        out = tf.keras.layers.GlobalAveragePooling2D(name = \"{0}gap\".format(name))(out)\n",
        "        if 0 < dropout_rate:\n",
        "            out = tf.keras.layers.Dropout(dropout_rate, name = \"{0}dropout\".format(name))(out)\n",
        "        out = tf.keras.layers.Dense(n_class, kernel_initializer = tf.keras.initializers.RandomNormal(mean = 0, stddev = 0.01), name = \"{0}logits\".format(name))(out)\n",
        "    return out\n",
        "\n",
        "def coatnet0(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 3, 5, 2], n_feature = [64, 96, 192, 384, 768], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet1(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 6, 14, 2], n_feature = [64, 96, 192, 384, 768], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet2(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 6, 14, 2], n_feature = [128, 128, 256, 512, 1024], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet3(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 6, 14, 2], n_feature = [192, 192, 384, 768, 1536], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet4(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 12, 28, 2], n_feature = [192, 192, 384, 768, 1536], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet5(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 12, 28, 2], n_feature = [192, 256, 512, 1280, 2048], block = [\"C\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = 2, expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet6(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 4, 8, 42, 2], n_feature = [192, 192, 384, 768, 1536, 2048], block = [\"C\", \"M\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = [2, 2, 2, 2, 1, 2], expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "def coatnet7(input_tensor = None, input_shape = None, classes = 1000, include_top = True, weights = None):\n",
        "    if input_tensor is None:\n",
        "        img_input = tf.keras.layers.Input(shape = input_shape)\n",
        "    else:\n",
        "        if not tf.keras.backend.is_keras_tensor(input_tensor):\n",
        "            img_input = tf.keras.layers.Input(tensor = input_tensor, shape = input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    out = coatnet(img_input, classes, include_top, n_depth = [2, 2, 4, 8, 42, 2], n_feature = [192, 256, 512, 1024, 2048, 3072], block = [\"C\", \"M\", \"M\", \"M\", \"T\", \"T\"], stage_stride_size = [2, 2, 2, 2, 1, 2], expand_ratio = 4, se_ratio = 4, dropout_rate = 0., activation = tf.keras.activations.gelu)\n",
        "    model = tf.keras.Model(img_input, out)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model"
      ],
      "metadata": {
        "id": "vi2oS_eS9Cqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/Shareddrives/519 project/train_COVIDx9A.txt', sep=\" \", header=None)\n",
        "\n",
        "#Columns are added because it was seen that column names were 0,1,2,3, so new column names are added\n",
        "#which are given in descriptions\n",
        "train_df.columns=['patient id', 'filename', 'class', 'data source']\n",
        "\n",
        "# Since we are doing image classification, patient id and data source is of no importance to us, so\n",
        "#we cn drop them\n",
        "train_df=train_df.drop(['patient id', 'data source'], axis=1 )"
      ],
      "metadata": {
        "id": "zdjMadGd9Ql2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OAkhyjYoA6AN",
        "outputId": "05804633-f929-43b0-df14-706671bfe7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            filename      class\n",
              "0  SARS-10.1148rg.242035193-g04mr34g0-Fig8a-day0....  pneumonia\n",
              "1  SARS-10.1148rg.242035193-g04mr34g0-Fig8b-day5....  pneumonia\n",
              "2  SARS-10.1148rg.242035193-g04mr34g0-Fig8c-day10...  pneumonia\n",
              "3  SARS-10.1148rg.242035193-g04mr34g04a-Fig4a-day...  pneumonia\n",
              "4  SARS-10.1148rg.242035193-g04mr34g04b-Fig4b-day...  pneumonia"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4835baf-7153-4c8c-8f24-1ea2a3a3b952\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARS-10.1148rg.242035193-g04mr34g0-Fig8a-day0....</td>\n",
              "      <td>pneumonia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARS-10.1148rg.242035193-g04mr34g0-Fig8b-day5....</td>\n",
              "      <td>pneumonia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARS-10.1148rg.242035193-g04mr34g0-Fig8c-day10...</td>\n",
              "      <td>pneumonia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARS-10.1148rg.242035193-g04mr34g04a-Fig4a-day...</td>\n",
              "      <td>pneumonia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARS-10.1148rg.242035193-g04mr34g04b-Fig4b-day...</td>\n",
              "      <td>pneumonia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4835baf-7153-4c8c-8f24-1ea2a3a3b952')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4835baf-7153-4c8c-8f24-1ea2a3a3b952 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4835baf-7153-4c8c-8f24-1ea2a3a3b952');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/drive/Shareddrives/519 project/test_COVIDx9A.txt', sep=\" \", header=None)\n",
        "test_df.columns=['id', 'filename', 'class', 'data source' ]\n",
        "test_df=test_df.drop(['id', 'data source'], axis=1 )"
      ],
      "metadata": {
        "id": "TQJz9DvUBZ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5vKQlT2LA7OE",
        "outputId": "7c318fbe-6a48-47c5-c8f7-c800975186d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    filename     class\n",
              "0  MIDRC-RICORD-1C-419639-003251-46647-0.png  COVID-19\n",
              "1  MIDRC-RICORD-1C-419639-001464-39871-0.png  COVID-19\n",
              "2  MIDRC-RICORD-1C-419639-000918-78965-0.png  COVID-19\n",
              "3  MIDRC-RICORD-1C-419639-003318-64285-0.png  COVID-19\n",
              "4  MIDRC-RICORD-1C-419639-001015-81591-0.png  COVID-19"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88714409-9b8e-4ef8-a649-8b6dd59c9ec4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MIDRC-RICORD-1C-419639-003251-46647-0.png</td>\n",
              "      <td>COVID-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MIDRC-RICORD-1C-419639-001464-39871-0.png</td>\n",
              "      <td>COVID-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MIDRC-RICORD-1C-419639-000918-78965-0.png</td>\n",
              "      <td>COVID-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MIDRC-RICORD-1C-419639-003318-64285-0.png</td>\n",
              "      <td>COVID-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MIDRC-RICORD-1C-419639-001015-81591-0.png</td>\n",
              "      <td>COVID-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88714409-9b8e-4ef8-a649-8b6dd59c9ec4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88714409-9b8e-4ef8-a649-8b6dd59c9ec4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88714409-9b8e-4ef8-a649-8b6dd59c9ec4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A26CXFzlBhHi",
        "outputId": "2f848772-0015-4a4e-ecbf-ec9ac9a9c3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COVID-19     16490\n",
              "normal        8085\n",
              "pneumonia     5555\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covid  = train_df[train_df['class']=='COVID-19']   #negative values in class column\n",
        "normal = train_df[train_df['class']=='normal']  #positive values in class column\n",
        "pneumonia = train_df[train_df['class']=='pneumonia']\n",
        "from sklearn.utils import resample\n",
        "#majority class that  is negative, we need to downsample/decrease that class so that there is no bias\n",
        "#n_samples = 2158 means we want 2158 sample of class negative, since there are 2158 samples of class positive\n",
        "df_covid_downsampled = resample(covid, replace = True, n_samples = 5555) \n",
        "df_normal_downsampled = resample(normal, replace = True, n_samples = 5555)\n",
        "#concatenate\n",
        "train_df = pd.concat([pneumonia, df_covid_downsampled,df_normal_downsampled])\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "train_df = shuffle(train_df) # shuffling so that there is particular sequence"
      ],
      "metadata": {
        "id": "JVfO7kZjBivO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2H-gc8gBjmW",
        "outputId": "a82b6df7-b50f-41c8-ca4c-ceebaf0704a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pneumonia    5555\n",
              "COVID-19     5555\n",
              "normal       5555\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data = train_test_split(train_df, train_size=0.8, random_state=0)"
      ],
      "metadata": {
        "id": "oHm916DUBlWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/Shareddrives/519 project/train_30000/'  #directory path\n",
        "test_path = '/content/drive/Shareddrives/519 project/test.zip (Unzipped Files)'"
      ],
      "metadata": {
        "id": "z4Ry5eP5BsxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, \n",
        "                                   #shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255., shear_range = 0.2)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "#Now fit the them to get the images from directory (name of the images are given in dataframe) with augmentation\n",
        "\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(dataframe = train_data, directory=train_path, x_col='filename', \n",
        "                                              y_col='class', target_size=(224,224), batch_size=16, \n",
        "                                               classes=['COVID-19','normal','pneumonia'],class_mode='sparse')\n",
        "valid_gen = test_datagen.flow_from_dataframe(dataframe = valid_data, directory=train_path, x_col='filename',\n",
        "                                             y_col='class', target_size=(224,224), batch_size=16, \n",
        "                                            classes=['COVID-19','normal','pneumonia'],class_mode='sparse')\n",
        "test_gen = test_datagen.flow_from_dataframe(dataframe = test_df, directory=test_path, x_col='filename', \n",
        "                                            y_col='class', target_size=(224,224), batch_size=1,\n",
        "                                             classes=['COVID-19','normal','pneumonia'],class_mode='sparse')"
      ],
      "metadata": {
        "id": "l5qGWTmiBwQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb10290-998a-423a-b092-d8e66d03120e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 10712 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2620 validated image filenames belonging to 3 classes.\n",
            "Found 650 validated image filenames belonging to 3 classes.\n",
            "Found 400 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2683 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen1 = train_datagen.flow_from_dataframe(dataframe = train_data, directory=train_path, x_col='filename', \n",
        "                                              y_col='class', target_size=(224,224), batch_size=4, \n",
        "                                               classes=['COVID-19','normal','pneumonia'],class_mode='sparse')\n",
        "valid_gen1 = test_datagen.flow_from_dataframe(dataframe = valid_data, directory=train_path, x_col='filename',\n",
        "                                             y_col='class', target_size=(224,224), batch_size=4, \n",
        "                                            classes=['COVID-19','normal','pneumonia'],class_mode='sparse')\n",
        "test_gen1 = test_datagen.flow_from_dataframe(dataframe = test_df, directory=test_path, x_col='filename', \n",
        "                                            y_col='class', target_size=(224,224), batch_size=1,\n",
        "                                             classes=['COVID-19','normal','pneumonia'],class_mode='sparse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyqrREtoAVux",
        "outputId": "ebaadc02-8479-43dd-a82d-6ac6feb62285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 10712 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2620 validated image filenames belonging to 3 classes.\n",
            "Found 650 validated image filenames belonging to 3 classes.\n",
            "Found 400 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2683 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = coatnet0(input_shape = (224, 224, 3), include_top = False)\n",
        "flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "dense = tf.keras.layers.Dense(128, activation = \"relu\")(flatten)\n",
        "drop_out = tf.keras.layers.Dropout(0.2)(dense)\n",
        "prediction = tf.keras.layers.Dense(3, activation = \"softmax\", name = \"prediction\")(drop_out)\n",
        "model = tf.keras.Model(model.input, prediction)"
      ],
      "metadata": {
        "id": "63et1kdPBzry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "opt = tf.keras.optimizers.Adam(7e-6)\n",
        "metric = [tf.keras.metrics.sparse_categorical_accuracy]\n",
        "weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(train_gen.classes), y = train_gen.classes)\n",
        "cw = dict(zip(np.unique(train_gen.classes), weights))\n",
        "callbacks = [\n",
        "    #tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h1\", save_best_only=True, verbose = 0),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode = \"min\", verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "model.compile(optimizer = opt, loss = loss,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qc2geV0MCyqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen, validation_data = valid_gen, epochs = 15, class_weight=cw, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "p26THSNoDFQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377ea49a-2333-47ec-bb9d-2eea7a7af467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "167/167 [==============================] - 1654s 10s/step - loss: 0.8823 - accuracy: 0.6032 - val_loss: 0.7200 - val_accuracy: 0.6813 - lr: 7.0000e-06\n",
            "Epoch 2/15\n",
            "167/167 [==============================] - 146s 873ms/step - loss: 0.6584 - accuracy: 0.7231 - val_loss: 0.5107 - val_accuracy: 0.7932 - lr: 7.0000e-06\n",
            "Epoch 3/15\n",
            "167/167 [==============================] - 149s 892ms/step - loss: 0.5627 - accuracy: 0.7737 - val_loss: 0.4761 - val_accuracy: 0.8003 - lr: 7.0000e-06\n",
            "Epoch 4/15\n",
            "167/167 [==============================] - 146s 874ms/step - loss: 0.5251 - accuracy: 0.7842 - val_loss: 0.4909 - val_accuracy: 0.7918 - lr: 7.0000e-06\n",
            "Epoch 5/15\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.7891\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 3.5000000480067683e-06.\n",
            "167/167 [==============================] - 146s 870ms/step - loss: 0.4954 - accuracy: 0.7891 - val_loss: 0.4899 - val_accuracy: 0.8017 - lr: 7.0000e-06\n",
            "Epoch 6/15\n",
            "167/167 [==============================] - 146s 870ms/step - loss: 0.4332 - accuracy: 0.8288 - val_loss: 0.4158 - val_accuracy: 0.8300 - lr: 3.5000e-06\n",
            "Epoch 7/15\n",
            "167/167 [==============================] - 145s 868ms/step - loss: 0.4154 - accuracy: 0.8318 - val_loss: 0.4175 - val_accuracy: 0.8300 - lr: 3.5000e-06\n",
            "Epoch 8/15\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.8314\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.7500000240033842e-06.\n",
            "167/167 [==============================] - 145s 869ms/step - loss: 0.4081 - accuracy: 0.8314 - val_loss: 0.4357 - val_accuracy: 0.8187 - lr: 3.5000e-06\n",
            "Epoch 9/15\n",
            "167/167 [==============================] - 145s 867ms/step - loss: 0.3914 - accuracy: 0.8456 - val_loss: 0.4081 - val_accuracy: 0.8456 - lr: 1.7500e-06\n",
            "Epoch 10/15\n",
            "167/167 [==============================] - 145s 868ms/step - loss: 0.3816 - accuracy: 0.8524 - val_loss: 0.3997 - val_accuracy: 0.8499 - lr: 1.7500e-06\n",
            "Epoch 11/15\n",
            "167/167 [==============================] - 145s 868ms/step - loss: 0.3753 - accuracy: 0.8464 - val_loss: 0.3856 - val_accuracy: 0.8598 - lr: 1.7500e-06\n",
            "Epoch 12/15\n",
            "167/167 [==============================] - 145s 867ms/step - loss: 0.3771 - accuracy: 0.8494 - val_loss: 0.4255 - val_accuracy: 0.8371 - lr: 1.7500e-06\n",
            "Epoch 13/15\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.8490\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.750000120016921e-07.\n",
            "167/167 [==============================] - 145s 868ms/step - loss: 0.3773 - accuracy: 0.8490 - val_loss: 0.3900 - val_accuracy: 0.8428 - lr: 1.7500e-06\n",
            "Epoch 14/15\n",
            "167/167 [==============================] - 145s 868ms/step - loss: 0.3500 - accuracy: 0.8651 - val_loss: 0.3959 - val_accuracy: 0.8484 - lr: 8.7500e-07\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97fa2ee090>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet: 12 Epochs; Train_acc: 0.9674; Val_acc:0.9215; Test_acc:0.8550\n",
        "model.evaluate(test_gen)"
      ],
      "metadata": {
        "id": "yPFwRPsDHOU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa9807e-fb80-4025-c5bb-b97cf98821ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400/400 [==============================] - 338s 843ms/step - loss: 0.3364 - accuracy: 0.8650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33641260862350464, 0.8650000095367432]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CoAtNet0: 15 Epochs; Train_acc: 0.865; Val_acc:0.848; Test_acc:0.865"
      ],
      "metadata": {
        "id": "w2rKi7TYufbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights(\"covid_classifier_model.h6\")"
      ],
      "metadata": {
        "id": "iriWhRe10kGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.load_weights(\"covid_classifier_model.h6\")"
      ],
      "metadata": {
        "id": "_hPzIk1ZUxkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.evaluate(test_gen)"
      ],
      "metadata": {
        "id": "7wd5M8B-U4B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CoAtNet1: 15 Epochs; Train_acc: 0.862; Val_acc:0.854; Test_acc:0.8525"
      ],
      "metadata": {
        "id": "m5UvAIGSXk_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = coatnet1(input_shape = (224, 224, 3), include_top = False)\n",
        "flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "dense = tf.keras.layers.Dense(128, activation = \"relu\")(flatten)\n",
        "drop_out = tf.keras.layers.Dropout(0.2)(dense)\n",
        "prediction = tf.keras.layers.Dense(3, activation = \"softmax\", name = \"prediction\")(drop_out)\n",
        "model = tf.keras.Model(model.input, prediction)\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "opt = tf.keras.optimizers.Adam(7e-6)\n",
        "metric = [tf.keras.metrics.sparse_categorical_accuracy]\n",
        "weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(train_gen.classes), y = train_gen.classes)\n",
        "cw = dict(zip(np.unique(train_gen.classes), weights))\n",
        "callbacks = [\n",
        "    #tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h1\", save_best_only=True, verbose = 0),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode = \"min\", verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "model.compile(optimizer = opt, loss = loss,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "M5Gzn4aTXXYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen, validation_data = valid_gen, epochs = 15, class_weight=cw, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "u0JStk7qYAHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b6931c-0bdf-46af-f35c-6fac481c6431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "167/167 [==============================] - 278s 1s/step - loss: 0.9068 - accuracy: 0.5530 - val_loss: 0.7108 - val_accuracy: 0.6870 - lr: 7.0000e-06\n",
            "Epoch 2/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.7353 - accuracy: 0.6901 - val_loss: 0.6997 - val_accuracy: 0.7025 - lr: 7.0000e-06\n",
            "Epoch 3/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.6434 - accuracy: 0.7340 - val_loss: 0.5732 - val_accuracy: 0.7465 - lr: 7.0000e-06\n",
            "Epoch 4/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.5974 - accuracy: 0.7448 - val_loss: 0.5378 - val_accuracy: 0.8116 - lr: 7.0000e-06\n",
            "Epoch 5/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.5446 - accuracy: 0.7673 - val_loss: 0.4744 - val_accuracy: 0.8201 - lr: 7.0000e-06\n",
            "Epoch 6/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.5428 - accuracy: 0.7718 - val_loss: 0.4779 - val_accuracy: 0.8130 - lr: 7.0000e-06\n",
            "Epoch 7/15\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.8010\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.5000000480067683e-06.\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.4727 - accuracy: 0.8010 - val_loss: 0.5408 - val_accuracy: 0.7705 - lr: 7.0000e-06\n",
            "Epoch 8/15\n",
            "167/167 [==============================] - 236s 1s/step - loss: 0.4557 - accuracy: 0.8097 - val_loss: 0.4105 - val_accuracy: 0.8456 - lr: 3.5000e-06\n",
            "Epoch 9/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.4180 - accuracy: 0.8359 - val_loss: 0.4310 - val_accuracy: 0.8201 - lr: 3.5000e-06\n",
            "Epoch 10/15\n",
            "167/167 [==============================] - 236s 1s/step - loss: 0.4117 - accuracy: 0.8374 - val_loss: 0.3922 - val_accuracy: 0.8513 - lr: 3.5000e-06\n",
            "Epoch 11/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.4000 - accuracy: 0.8396 - val_loss: 0.4141 - val_accuracy: 0.8329 - lr: 3.5000e-06\n",
            "Epoch 12/15\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8494\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.7500000240033842e-06.\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.3830 - accuracy: 0.8494 - val_loss: 0.4160 - val_accuracy: 0.8343 - lr: 3.5000e-06\n",
            "Epoch 13/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.3564 - accuracy: 0.8659 - val_loss: 0.3732 - val_accuracy: 0.8555 - lr: 1.7500e-06\n",
            "Epoch 14/15\n",
            "167/167 [==============================] - 236s 1s/step - loss: 0.3564 - accuracy: 0.8602 - val_loss: 0.3738 - val_accuracy: 0.8470 - lr: 1.7500e-06\n",
            "Epoch 15/15\n",
            "167/167 [==============================] - 237s 1s/step - loss: 0.3554 - accuracy: 0.8621 - val_loss: 0.3646 - val_accuracy: 0.8541 - lr: 1.7500e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f987ae03550>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CIshynbcCBR",
        "outputId": "bcdc7c45-2982-4c44-d5f8-12e0db050058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400/400 [==============================] - 48s 120ms/step - loss: 0.3897 - accuracy: 0.8525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38969185948371887, 0.8525000214576721]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CoAtNet2: 15 Epochs; Train_acc: 0.851; Val_acc:0.839; Test_acc:0.832"
      ],
      "metadata": {
        "id": "pLlFFU5RZ2BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = coatnet2(input_shape = (224, 224, 3), include_top = False)\n",
        "flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "dense = tf.keras.layers.Dense(128, activation = \"relu\")(flatten)\n",
        "drop_out = tf.keras.layers.Dropout(0.2)(dense)\n",
        "prediction = tf.keras.layers.Dense(3, activation = \"softmax\", name = \"prediction\")(drop_out)\n",
        "model = tf.keras.Model(model.input, prediction)\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "opt = tf.keras.optimizers.Adam(7e-6)\n",
        "metric = [tf.keras.metrics.sparse_categorical_accuracy]\n",
        "weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(train_gen.classes), y = train_gen.classes)\n",
        "cw = dict(zip(np.unique(train_gen.classes), weights))\n",
        "callbacks = [\n",
        "    #tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h1\", save_best_only=True, verbose = 0),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode = \"min\", verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "model.compile(optimizer = opt, loss = loss,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "I9NcqON4ZgE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen1, validation_data = valid_gen1, epochs = 15, class_weight=cw, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "aG4e1VOmZrb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2053bb4b-2e04-4091-e882-4746ab0f2089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "334/334 [==============================] - 468s 1s/step - loss: 0.8472 - accuracy: 0.5946 - val_loss: 0.7863 - val_accuracy: 0.6161 - lr: 7.0000e-06\n",
            "Epoch 2/15\n",
            "334/334 [==============================] - 367s 1s/step - loss: 0.7587 - accuracy: 0.6501 - val_loss: 0.7115 - val_accuracy: 0.6728 - lr: 7.0000e-06\n",
            "Epoch 3/15\n",
            "334/334 [==============================] - 369s 1s/step - loss: 0.7160 - accuracy: 0.6778 - val_loss: 0.7502 - val_accuracy: 0.6586 - lr: 7.0000e-06\n",
            "Epoch 4/15\n",
            "334/334 [==============================] - 368s 1s/step - loss: 0.6939 - accuracy: 0.6793 - val_loss: 0.6369 - val_accuracy: 0.7380 - lr: 7.0000e-06\n",
            "Epoch 5/15\n",
            "334/334 [==============================] - 369s 1s/step - loss: 0.7037 - accuracy: 0.6860 - val_loss: 0.6839 - val_accuracy: 0.6714 - lr: 7.0000e-06\n",
            "Epoch 6/15\n",
            "334/334 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.6699\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.5000000480067683e-06.\n",
            "334/334 [==============================] - 368s 1s/step - loss: 0.7323 - accuracy: 0.6699 - val_loss: 0.7748 - val_accuracy: 0.6813 - lr: 7.0000e-06\n",
            "Epoch 7/15\n",
            "334/334 [==============================] - 368s 1s/step - loss: 0.7645 - accuracy: 0.6579 - val_loss: 0.6882 - val_accuracy: 0.6870 - lr: 3.5000e-06\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97f8c0e510>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_gen)"
      ],
      "metadata": {
        "id": "kEyXNBcYcDLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CoAtNet3: 15 Epochs; Train_acc: 0.; Val_acc:0.; Test_acc:0."
      ],
      "metadata": {
        "id": "EQXGFyLuZ-wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = coatnet3(input_shape = (224, 224, 3), include_top = False)\n",
        "flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "dense = tf.keras.layers.Dense(128, activation = \"relu\")(flatten)\n",
        "drop_out = tf.keras.layers.Dropout(0.2)(dense)\n",
        "prediction = tf.keras.layers.Dense(3, activation = \"softmax\", name = \"prediction\")(drop_out)\n",
        "model = tf.keras.Model(model.input, prediction)\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "opt = tf.keras.optimizers.Adam(7e-6)\n",
        "metric = [tf.keras.metrics.sparse_categorical_accuracy]\n",
        "weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(train_gen.classes), y = train_gen.classes)\n",
        "cw = dict(zip(np.unique(train_gen.classes), weights))\n",
        "callbacks = [\n",
        "    #tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h1\", save_best_only=True, verbose = 0),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode = \"min\", verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "model.compile(optimizer = opt, loss = loss,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6cq1FMi9Zr3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen1, validation_data = valid_gen1, epochs = 15, class_weight=cw, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "shYI2tvpZs1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbee9ecf-52c9-46a5-cd5b-1399f3f2fee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "655/655 [==============================] - 1068s 2s/step - loss: 0.9575 - accuracy: 0.5168 - val_loss: 0.8483 - val_accuracy: 0.5785 - lr: 7.0000e-06\n",
            "Epoch 2/15\n",
            "655/655 [==============================] - 622s 949ms/step - loss: 0.8956 - accuracy: 0.5397 - val_loss: 0.8097 - val_accuracy: 0.5831 - lr: 7.0000e-06\n",
            "Epoch 3/15\n",
            "655/655 [==============================] - 619s 945ms/step - loss: 0.8844 - accuracy: 0.5630 - val_loss: 0.8155 - val_accuracy: 0.6015 - lr: 7.0000e-06\n",
            "Epoch 4/15\n",
            "655/655 [==============================] - ETA: 0s - loss: 0.8797 - accuracy: 0.5542\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 3.5000000480067683e-06.\n",
            "655/655 [==============================] - 619s 945ms/step - loss: 0.8797 - accuracy: 0.5542 - val_loss: 0.8663 - val_accuracy: 0.5323 - lr: 7.0000e-06\n",
            "Epoch 5/15\n",
            "655/655 [==============================] - 618s 944ms/step - loss: 0.9102 - accuracy: 0.5607 - val_loss: 0.8411 - val_accuracy: 0.6123 - lr: 3.5000e-06\n",
            "Epoch 5: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa322804890>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_gen1)"
      ],
      "metadata": {
        "id": "gtshhz2ZcDvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788c2cb3-0657-44d4-cea4-fc83935c799f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400/400 [==============================] - 194s 485ms/step - loss: 0.7206 - accuracy: 0.6100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7205551266670227, 0.6100000143051147]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CoAtNet4: 15 Epochs; Train_acc: 0.; Val_acc:0.; Test_acc:0."
      ],
      "metadata": {
        "id": "i_M6soYpaBz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = coatnet4(input_shape = (224, 224, 3), include_top = False)\n",
        "flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "dense = tf.keras.layers.Dense(128, activation = \"relu\")(flatten)\n",
        "drop_out = tf.keras.layers.Dropout(0.2)(dense)\n",
        "prediction = tf.keras.layers.Dense(3, activation = \"softmax\", name = \"prediction\")(drop_out)\n",
        "model = tf.keras.Model(model.input, prediction)\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "opt = tf.keras.optimizers.Adam(1e-5)\n",
        "metric = [tf.keras.metrics.sparse_categorical_accuracy]\n",
        "weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(train_gen.classes), y = train_gen.classes)\n",
        "cw = dict(zip(np.unique(train_gen.classes), weights))\n",
        "callbacks = [\n",
        "    #tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h1\", save_best_only=True, verbose = 0),\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', mode = \"min\", verbose=1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "model.compile(optimizer = opt, loss = loss,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "pPZuN2sTaBNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen1, validation_data = valid_gen1, epochs = 15, class_weight=cw, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "JMNx61TRaLIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bf0017-e1e2-4c73-bf45-4c5ff0162f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "655/655 [==============================] - 1079s 2s/step - loss: 1.1059 - accuracy: 0.3584 - val_loss: 1.0977 - val_accuracy: 0.3477 - lr: 1.0000e-05\n",
            "Epoch 2/15\n",
            "655/655 [==============================] - 991s 2s/step - loss: 1.1009 - accuracy: 0.3603 - val_loss: 1.0980 - val_accuracy: 0.3477 - lr: 1.0000e-05\n",
            "Epoch 3/15\n",
            "655/655 [==============================] - ETA: 0s - loss: 1.1009 - accuracy: 0.3137\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "655/655 [==============================] - 987s 2s/step - loss: 1.1009 - accuracy: 0.3137 - val_loss: 1.0986 - val_accuracy: 0.2600 - lr: 1.0000e-05\n",
            "Epoch 4/15\n",
            "655/655 [==============================] - 978s 1s/step - loss: 1.0986 - accuracy: 0.2527 - val_loss: 1.0986 - val_accuracy: 0.2600 - lr: 5.0000e-06\n",
            "Epoch 4: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa397242450>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_gen1)"
      ],
      "metadata": {
        "id": "C6yK64E0cEtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b566595b-6104-45ff-92c9-7d7080b8ff37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400/400 [==============================] - 88s 219ms/step - loss: 1.0987 - accuracy: 0.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0986504554748535, 0.25]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}